{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw/train.csv')\n",
    "test = pd.read_csv('../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(zip(train.columns.to_list(), train.dtypes.to_list()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data preprocessing + Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build_year outliers cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['build_year'].clip(train['build_year'].quantile(0.06), train['build_year'].quantile(0.99), inplace=True)\n",
    "train['build_year'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product_type (категориальная -> бинарная)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['product_type'] = train['product_type'].replace({'Investment': 1, 'OwnerOccupier': 0})\n",
    "test['product_type'] = test['product_type'].replace({'Investment': 1, 'OwnerOccupier': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "новая фича: Price m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['price_m2'] = train['price_doc'] / (train['full_sq'] + 1)\n",
    "train['price_m2'].clip(train['price_m2'].quantile(0.01), train['price_m2'].quantile(0.99), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target encoding (sub area) // Каково среднее значение price_m2 в каждой из sub_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(train, test, col_x, col_y):\n",
    "    col_target_encoding = train.groupby([col_x])[col_y].mean()\n",
    "\n",
    "    train[col_x] = train[col_x].replace(col_target_encoding)\n",
    "    test[col_x] = test[col_x].replace(col_target_encoding)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = target_encoding(train, test, 'sub_area', 'price_m2')\n",
    "train, test = target_encoding(train, test, 'material', 'price_m2')\n",
    "train, test = target_encoding(train, test, 'state', 'price_m2')\n",
    "train, test = target_encoding(train, test, 'ID_metro', 'price_m2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamp encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_time_features(timestamp_series: pd.Series) -> pd.DataFrame:\n",
    "    \n",
    "    timestamp_series = pd.to_datetime(timestamp_series)\n",
    "    \n",
    "    output= pd.DataFrame()\n",
    "    output['timestamp']= timestamp_series\n",
    "    output['month'] = timestamp_series.dt.month.astype(np.int8)\n",
    "#     output['hour_datetime'] = timestamp_series.dt.hour.astype(np.int8)  \n",
    "    output['day_week'] = timestamp_series.dt.dayofweek.astype(np.int8)\n",
    "    output['day_month_datetime'] =timestamp_series.dt.day.astype(np.int8)\n",
    "    output['year'] = timestamp_series.dt.year.astype(np.int16)\n",
    "#     _min = timestamp_series.iloc[0].astype(int)/1_000_000_000_000\n",
    "    output['kseconds'] = timestamp_series.view(int)/1_000_000_000_000\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat( [train, get_date_time_features(train['timestamp'])] , axis=1 )\n",
    "test = pd.concat( [test, get_date_time_features(test['timestamp'])] , axis=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['floor_height'] = train['floor'] / (train['max_floor'] + 1)\n",
    "test['floor_height'] = test['floor'] / (test['max_floor'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['life_part'] = train['life_sq'] / (train['full_sq'] + 1)\n",
    "train['kitch_part'] = train['kitch_sq'] / (train['full_sq'] + 1)\n",
    "\n",
    "test['life_part'] = test['life_sq'] / (test['full_sq'] + 1)\n",
    "test['kitch_part'] = test['kitch_sq'] / (test['full_sq'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x_col = ['kseconds',\n",
    "         'sub_area',\n",
    "         'product_type',\n",
    "         'build_year',\n",
    "         'material',\n",
    "         'num_room',\n",
    "         'floor_height',\n",
    "         'life_part',\n",
    "         'kitch_part', \n",
    "         'kremlin_km',\n",
    "         'metro_km_walk', \n",
    "         'state', \n",
    "         'ID_metro',\n",
    "         'price_m2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HeatMap of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train = train[all_x_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.heatmap(XY_train.corr(), cmap=\"YlGnBu\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train[all_x_col].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'build_year'] = train['build_year'].fillna(train['build_year'].median())\n",
    "train.loc[:, 'material'] = train['material'].fillna(train['material'].median())\n",
    "train.loc[:, 'num_room'] = train['num_room'].fillna(train['num_room'].median())\n",
    "train.loc[:, 'floor_height'] = train['floor_height'].fillna(train['floor_height'].median())\n",
    "train.loc[:, 'life_part'] = train['life_part'].fillna(train['life_part'].median())\n",
    "train.loc[:, 'kitch_part'] = train['kitch_part'].fillna(train['kitch_part'].median())\n",
    "train.loc[:, 'metro_km_walk'] = train['metro_km_walk'].fillna(train['metro_km_walk'].median())\n",
    "train.loc[:, 'state'] = train['state'].fillna(train['state'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[all_x_col].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(df, x_col, y_col):\n",
    "    features = x_col\n",
    "    target = y_col\n",
    "\n",
    "    mse_list = []\n",
    "    msle_list = []\n",
    "    i = 1\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        train_part = df.loc[train_idx, :]\n",
    "        val_part = df.loc[val_idx, :]\n",
    "\n",
    "        model = SGDRegressor()\n",
    "        model.fit(X=train_part[features], y=train_part[target])\n",
    "        val_pred = model.predict(val_part[features]).clip(1, 10**9)\n",
    "\n",
    "        mse = mean_squared_error(val_pred, val_part[target])\n",
    "        msle = mean_squared_log_error(val_pred, val_part[target])\n",
    "\n",
    "        mse_list.append(mse)\n",
    "        msle_list.append(msle)\n",
    "\n",
    "        print(f'Fold: {i}, MSLE: {msle}, MSE: {mse}')\n",
    "        i += 1\n",
    "\n",
    "    print(f'AV_MSLE: {np.mean(msle_list)}, AV_MSE: {np.mean(mse_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test 5 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col1 = ['metro_km_walk', 'kremlin_km', 'num_room']\n",
    "y_col = 'price_m2'\n",
    "\n",
    "cross_validation(train, x_col1, y_col)\n",
    "\n",
    "model1 = SGDRegressor()\n",
    "model1.fit(X=train[x_col1], y=train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col2 = ['metro_km_walk', 'kremlin_km', 'num_room']\n",
    "y_col = 'price_m2'\n",
    "\n",
    "train.loc[:, 'metro_km_walk'] = (train['metro_km_walk'] - train['metro_km_walk'].mean()) / train['metro_km_walk'].std()\n",
    "train.loc[:, 'kremlin_km'] = (train['kremlin_km'] - train['kremlin_km'].mean()) / train['kremlin_km'].std()\n",
    "\n",
    "cross_validation(train, x_col2, y_col)\n",
    "\n",
    "model2 = SGDRegressor()\n",
    "model2.fit(X=train[x_col2], y=train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col3 = ['sub_area',\n",
    "         'product_type',\n",
    "         'state',\n",
    "         'ID_metro',\n",
    "         'material',\n",
    "         'num_room',\n",
    "         'kremlin_km',\n",
    "         'metro_km_walk']\n",
    "y_col = 'price_m2'\n",
    "\n",
    "train.loc[:, 'sub_area'] = (train['sub_area'] - train['sub_area'].mean()) / train['sub_area'].std()\n",
    "train.loc[:, 'state'] = (train['state'] - train['state'].mean()) / train['state'].std()\n",
    "train.loc[:, 'ID_metro'] = (train['ID_metro'] - train['ID_metro'].mean()) / train['ID_metro'].std()\n",
    "train.loc[:, 'material'] = (train['material'] - train['material'].mean()) / train['material'].std()\n",
    "\n",
    "cross_validation(train, x_col3, y_col)\n",
    "model3 = SGDRegressor()\n",
    "model3.fit(X=train[x_col3], y=train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col4 = ['sub_area',\n",
    "         'product_type',\n",
    "         'state',\n",
    "         'ID_metro',\n",
    "         'material',\n",
    "         'num_room',\n",
    "         'kremlin_km',\n",
    "         'metro_km_walk',\n",
    "        'kseconds',\n",
    "        'build_year']\n",
    "y_col = 'price_m2'\n",
    "\n",
    "train.loc[:, 'kseconds'] = (train['kseconds'] - train['kseconds'].mean()) / train['kseconds'].std()\n",
    "train.loc[:, 'build_year'] = (train['build_year'] - train['build_year'].mean()) / train['build_year'].std()\n",
    "\n",
    "cross_validation(train, x_col4, y_col)\n",
    "model4 = SGDRegressor()\n",
    "model4.fit(X=train[x_col4], y=train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Test 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col5 = ['sub_area',\n",
    "         'product_type',\n",
    "         'state',\n",
    "         'ID_metro',\n",
    "         'material',\n",
    "         'num_room',\n",
    "         'kremlin_km',\n",
    "         'metro_km_walk',\n",
    "        'kseconds',\n",
    "        'build_year']\n",
    "\n",
    "train['log_price_m2'] = np.log1p(train['price_m2'])\n",
    "\n",
    "y_col = 'log_price_m2'\n",
    "\n",
    "\n",
    "cross_validation(train, x_col5, y_col)\n",
    "model5 = SGDRegressor()\n",
    "model5.fit(X=train[x_col5], y=train[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CV + submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test(test, model, x_col, i):\n",
    "    test_prediction = model.predict(test[x_col].fillna(0))\n",
    "    sample_submission = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "    sample_submission['price_doc'] = test_prediction\n",
    "    sample_submission['price_doc'] *= test['full_sq']\n",
    "    sample_submission['price_doc'] = sample_submission['price_doc'].clip(1, 10**9)\n",
    "    sample_submission.to_csv(f'predict_hw_model{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_logtarget(test, model, x_col, i):\n",
    "    test_prediction = model.predict(test[x_col].fillna(0))\n",
    "    sample_submission = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "    sample_submission['price_doc'] = np.e**test_prediction - 1\n",
    "    sample_submission['price_doc'] *= test['full_sq']\n",
    "    sample_submission['price_doc'] = sample_submission['price_doc'].clip(1, 10**9)\n",
    "    sample_submission.to_csv(f'predict_hw_model{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'metro_km_walk'] = (test['metro_km_walk'] - test['metro_km_walk'].mean()) / test['metro_km_walk'].std()\n",
    "test.loc[:, 'kremlin_km'] = (test['kremlin_km'] - test['kremlin_km'].mean()) / test['kremlin_km'].std()\n",
    "test.loc[:, 'sub_area'] = (test['sub_area'] - test['sub_area'].mean()) / test['sub_area'].std()\n",
    "test.loc[:, 'state'] = (test['state'] - test['state'].mean()) / test['state'].std()\n",
    "test.loc[:, 'ID_metro'] = (test['ID_metro'] - test['ID_metro'].mean()) / test['ID_metro'].std()\n",
    "test.loc[:, 'material'] = (test['material'] - test['material'].mean()) / test['material'].std()\n",
    "test.loc[:, 'kseconds'] = (test['kseconds'] - test['kseconds'].mean()) / test['kseconds'].std()\n",
    "test.loc[:, 'build_year'] = (test['build_year'] - test['build_year'].mean()) / test['build_year'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test(test, model1, x_col1, 1)\n",
    "write_test(test, model2, x_col2, 2)\n",
    "write_test(test, model3, x_col3, 3)\n",
    "write_test(test, model4, x_col4, 4)\n",
    "write_test_logtarget(test, model5, x_col5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plot submit_score(CV_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['1', '2', '3', '4', '5']\n",
    "CV_scores = [0.28854592971311366, 0.3465958289811607, 0.22271291419476152, 0.21919826596823824, 0.21129017297138314]\n",
    "submit_scores = [0.37263, 0.36283, 0.33540, 0.33954, 0.35458]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(models, CV_scores, submit_scores)), columns=['model', 'CV', 'submit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='model', y=['CV', 'submit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Категориальные переменные сильно снизили ошибку<br>\n",
    "2) Из-за использования DateTime переменных модель переобучается<br>\n",
    "3) Логарифмирование таргета ухудшило результат на сабмите"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}